+ source /anvil/scratch/x-qlan1/moule/train-env/bin/activate
++ '[' -z '' ']'
++ '[' -n x ']'
++ SCRIPT_PATH=/anvil/scratch/x-qlan1/moule/train-env/bin/activate
++ '[' /anvil/scratch/x-qlan1/moule/train-env/bin/activate = /var/spool/slurm/job15363063/slurm_script ']'
++ deactivate nondestructive
++ unset -f pydoc
++ '[' -z '' ']'
++ '[' -z '' ']'
++ hash -r
++ '[' -z '' ']'
++ unset VIRTUAL_ENV
++ unset VIRTUAL_ENV_PROMPT
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/anvil/scratch/x-qlan1/moule/train-env
++ '[' linux-gnu = cygwin ']'
++ '[' linux-gnu = msys ']'
++ export VIRTUAL_ENV
++ '[' -z '' ']'
++ unset SCRIPT_PATH
++ _OLD_VIRTUAL_PATH=/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/home/x-qlan1/.vscode-server/cli/servers/Stable-c3a26841a84f20dfe0850d0a5a9bd01da4f003ea/server/bin/remote-cli:/home/x-qlan1/miniconda3/bin:/home/x-qlan1/miniconda3/condabin:/apps/anvil/external/apps/xalt2/xalt/xalt/bin:/apps/spack/anvil/apps/openmpi/4.0.6-gcc-11.2.0-3navcwb/bin:/apps/spack/anvil/apps/numactl/2.0.14-gcc-11.2.0-wrjotmv/bin:/apps/spack/anvil/apps/libfabric/1.12.0-gcc-8.4.1-xj6lmd4/bin:/apps/spack/anvil/apps/gcc/11.2.0-gcc-8.4.1-qjtdkvs/bin:/home/x-qlan1/bin:/home/x-qlan1/.local/bin:/usr/libexec/gsissh/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/usr/site/rcac/sbin:/usr/site/rcac/bin:/usr/site/rcac/scripts:/opt/thinlinc/bin:/opt/thinlinc/sbin:/home/x-qlan1/.vscode-server/extensions/ms-python.debugpy-2025.18.0-linux-x64/bundled/scripts/noConfigScripts
++ PATH=/anvil/scratch/x-qlan1/moule/train-env/bin:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/home/x-qlan1/.vscode-server/cli/servers/Stable-c3a26841a84f20dfe0850d0a5a9bd01da4f003ea/server/bin/remote-cli:/home/x-qlan1/miniconda3/bin:/home/x-qlan1/miniconda3/condabin:/apps/anvil/external/apps/xalt2/xalt/xalt/bin:/apps/spack/anvil/apps/openmpi/4.0.6-gcc-11.2.0-3navcwb/bin:/apps/spack/anvil/apps/numactl/2.0.14-gcc-11.2.0-wrjotmv/bin:/apps/spack/anvil/apps/libfabric/1.12.0-gcc-8.4.1-xj6lmd4/bin:/apps/spack/anvil/apps/gcc/11.2.0-gcc-8.4.1-qjtdkvs/bin:/home/x-qlan1/bin:/home/x-qlan1/.local/bin:/usr/libexec/gsissh/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/usr/site/rcac/sbin:/usr/site/rcac/bin:/usr/site/rcac/scripts:/opt/thinlinc/bin:/opt/thinlinc/sbin:/home/x-qlan1/.vscode-server/extensions/ms-python.debugpy-2025.18.0-linux-x64/bundled/scripts/noConfigScripts
++ export PATH
++ '[' x '!=' x ']'
+++ basename /anvil/scratch/x-qlan1/moule/train-env
++ VIRTUAL_ENV_PROMPT=train-env
++ export VIRTUAL_ENV_PROMPT
++ '[' -z '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ PS1='(train-env) '
++ export PS1
++ alias pydoc
++ true
++ hash -r
+ SCRATCH=/anvil/scratch/x-qlan1/moule
+ export HF_HOME=/anvil/scratch/x-qlan1/moule/hf_cache
+ HF_HOME=/anvil/scratch/x-qlan1/moule/hf_cache
+ export HF_DATASETS_CACHE=/anvil/scratch/x-qlan1/moule/hf_cache/datasets
+ HF_DATASETS_CACHE=/anvil/scratch/x-qlan1/moule/hf_cache/datasets
+ export TRANSFORMERS_CACHE=/anvil/scratch/x-qlan1/moule/hf_cache
+ TRANSFORMERS_CACHE=/anvil/scratch/x-qlan1/moule/hf_cache
+ export LD_PRELOAD=/home/x-qlan1/miniconda3/lib/libstdc++.so.6
+ LD_PRELOAD=/home/x-qlan1/miniconda3/lib/libstdc++.so.6
+ SCRIPT_DIR=/home/x-qlan1/code/moule2/teacher_uncertainty_each-sample
+ echo ==========================================
==========================================
+ echo 'Computing teacher uncertainty (SE)'
Computing teacher uncertainty (SE)
+ echo ==========================================
==========================================
+ python3 /home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/compute_uncertainty.py --teacher_model Qwen/Qwen3-8B --tp 1 --max_model_len 4096 --gpu_memory_utilization 0.65 --cluster_model Qwen/Qwen2.5-3B-Instruct --n_samples 8 --temperature 0.7 --max_gen_tokens 1650 --input /home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/evolved_clean.jsonl --output /home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/evolved_with_se.jsonl --batch_size 1024
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading /home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/evolved_clean.jsonl...
Loaded 45628 entries
Resuming: 1121 already done, skipping...
Entries to process: 44507
Loading teacher: Qwen/Qwen3-8B (TP=1)
INFO 02-20 15:56:12 [__init__.py:216] Automatically detected platform cuda.
INFO 02-20 15:56:21 [utils.py:233] non-default args: {'trust_remote_code': True, 'dtype': 'bfloat16', 'max_model_len': 4096, 'gpu_memory_utilization': 0.65, 'disable_log_stats': True, 'model': 'Qwen/Qwen3-8B'}
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
INFO 02-20 15:56:22 [model.py:547] Resolved architecture: Qwen3ForCausalLM
`torch_dtype` is deprecated! Use `dtype` instead!
INFO 02-20 15:56:22 [model.py:1510] Using max model len 4096
INFO 02-20 15:56:23 [scheduler.py:205] Chunked prefill is enabled with max_num_batched_tokens=16384.
WARNING 02-20 15:56:23 [__init__.py:3036] We must use the `spawn` multiprocessing start method. Overriding VLLM_WORKER_MULTIPROC_METHOD to 'spawn'. See https://docs.vllm.ai/en/latest/usage/troubleshooting.html#python-multiprocessing for more information. Reasons: CUDA is initialized
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
INFO 02-20 15:56:39 [__init__.py:216] Automatically detected platform cuda.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m INFO 02-20 15:56:43 [core.py:644] Waiting for init message from front-end.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m INFO 02-20 15:56:43 [core.py:77] Initializing a V1 LLM engine (v0.11.0) with config: model='Qwen/Qwen3-8B', speculative_config=None, tokenizer='Qwen/Qwen3-8B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, structured_outputs_config=StructuredOutputsConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_parser=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=Qwen/Qwen3-8B, enable_prefix_caching=True, chunked_prefill_enabled=True, pooler_config=None, compilation_config={"level":3,"debug_dump_path":"","cache_dir":"","backend":"","custom_ops":[],"splitting_ops":["vllm.unified_attention","vllm.unified_attention_with_output","vllm.mamba_mixer2","vllm.mamba_mixer","vllm.short_conv","vllm.linear_attention","vllm.plamo2_mamba_mixer","vllm.gdn_attention","vllm.sparse_attn_indexer"],"use_inductor":true,"compile_sizes":[],"inductor_compile_config":{"enable_auto_functionalized_v2":false},"inductor_passes":{},"cudagraph_mode":[2,1],"use_cudagraph":true,"cudagraph_num_of_warmups":1,"cudagraph_capture_sizes":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],"cudagraph_copy_inputs":false,"full_cuda_graph":false,"use_inductor_graph_partition":false,"pass_config":{},"max_capture_size":512,"local_cache_dir":null}
[1;36m(EngineCore_DP0 pid=1739467)[0;0m W0220 15:56:48.234000 1739467 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
[1;36m(EngineCore_DP0 pid=1739467)[0;0m W0220 15:56:48.234000 1739467 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] EngineCore failed to start.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 699, in run_engine_core
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     self._init_executor()
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 54, in _init_executor
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     self.collective_rpc("init_device")
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/worker/worker_base.py", line 259, in init_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 161, in init_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     current_platform.set_device(self.device)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/platforms/cuda.py", line 79, in set_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     torch.cuda.set_device(device)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py", line 569, in set_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708]     torch._C._cuda_setDevice(device)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] torch.AcceleratorError: CUDA error: out of memory
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m ERROR 02-20 15:56:49 [core.py:708] 
[1;36m(EngineCore_DP0 pid=1739467)[0;0m Process EngineCore_DP0:
[1;36m(EngineCore_DP0 pid=1739467)[0;0m Traceback (most recent call last):
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/home/x-qlan1/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     self.run()
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/home/x-qlan1/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/multiprocessing/process.py", line 108, in run
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     self._target(*self._args, **self._kwargs)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 712, in run_engine_core
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     raise e
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 699, in run_engine_core
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     engine_core = EngineCoreProc(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 498, in __init__
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     super().__init__(vllm_config, executor_class, log_stats,
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core.py", line 83, in __init__
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     self.model_executor = executor_class(vllm_config)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/executor/executor_base.py", line 54, in __init__
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     self._init_executor()
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 54, in _init_executor
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     self.collective_rpc("init_device")
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/executor/uniproc_executor.py", line 83, in collective_rpc
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     return [run_method(self.driver_worker, method, args, kwargs)]
[1;36m(EngineCore_DP0 pid=1739467)[0;0m             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/utils/__init__.py", line 3122, in run_method
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     return func(*args, **kwargs)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m            ^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/worker/worker_base.py", line 259, in init_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     self.worker.init_device()  # type: ignore
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     ^^^^^^^^^^^^^^^^^^^^^^^^^
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/worker/gpu_worker.py", line 161, in init_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     current_platform.set_device(self.device)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/platforms/cuda.py", line 79, in set_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     torch.cuda.set_device(device)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m   File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py", line 569, in set_device
[1;36m(EngineCore_DP0 pid=1739467)[0;0m     torch._C._cuda_setDevice(device)
[1;36m(EngineCore_DP0 pid=1739467)[0;0m torch.AcceleratorError: CUDA error: out of memory
[1;36m(EngineCore_DP0 pid=1739467)[0;0m CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m For debugging consider passing CUDA_LAUNCH_BLOCKING=1
[1;36m(EngineCore_DP0 pid=1739467)[0;0m Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
[1;36m(EngineCore_DP0 pid=1739467)[0;0m 
Traceback (most recent call last):
  File "/home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/compute_uncertainty.py", line 332, in <module>
    main(args)
  File "/home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/compute_uncertainty.py", line 194, in main
    teacher_llm = LLM(
                  ^^^^
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/entrypoints/llm.py", line 297, in __init__
    self.llm_engine = LLMEngine.from_engine_args(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py", line 177, in from_engine_args
    return cls(vllm_config=vllm_config,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py", line 114, in __init__
    self.engine_core = EngineCoreClient.make_client(
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 80, in make_client
    return SyncMPClient(vllm_config, executor_class, log_stats)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 602, in __init__
    super().__init__(
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/core_client.py", line 448, in __init__
    with launch_core_engines(vllm_config, executor_class,
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/x-qlan1/.local/share/uv/python/cpython-3.12.12-linux-x86_64-gnu/lib/python3.12/contextlib.py", line 144, in __exit__
    next(self.gen)
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 732, in launch_core_engines
    wait_for_engine_startup(
  File "/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/vllm/v1/engine/utils.py", line 785, in wait_for_engine_startup
    raise RuntimeError("Engine core initialization failed. "
RuntimeError: Engine core initialization failed. See root cause above. Failed core proc(s): {}
+ echo ==========================================
==========================================
+ echo 'Done!'
Done!
+ echo ==========================================
==========================================
+ echo 'Output: /home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/evolved_with_se.jsonl'
Output: /home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/evolved_with_se.jsonl
++ wc -l
+ echo 'Count:  1121'
Count:  1121
+ echo ''

+ echo 'SE distribution:'
SE distribution:
+ python3 -c '
import json
with open('\''/home/x-qlan1/code/moule2/teacher_uncertainty_each-sample/evolved_with_se.jsonl'\'') as f:
    ses = [json.loads(l)['\''se'\''] for l in f if l.strip()]
n = len(ses)
if n == 0:
    print('\''  No samples produced â€” check for errors above.'\'')
else:
    avg = sum(ses)/n
    low = sum(1 for s in ses if s < 0.1)
    mid = sum(1 for s in ses if 0.1 <= s < 0.5)
    high = sum(1 for s in ses if s >= 0.5)
    print(f'\''  Total: {n}'\'')
    print(f'\''  Avg SE: {avg:.3f}, Avg weight: {1-avg:.3f}'\'')
    print(f'\''  Confident (SE<0.1): {low} ({low/n:.1%})'\'')
    print(f'\''  Moderate (0.1<=SE<0.5): {mid} ({mid/n:.1%})'\'')
    print(f'\''  Uncertain (SE>=0.5): {high} ({high/n:.1%})'\'')
'
  Total: 1121
  Avg SE: 0.232, Avg weight: 0.768
  Confident (SE<0.1): 631 (56.3%)
  Moderate (0.1<=SE<0.5): 257 (22.9%)
  Uncertain (SE>=0.5): 233 (20.8%)
