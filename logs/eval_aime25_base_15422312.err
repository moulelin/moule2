+ mkdir -p /home/x-qlan1/code/moule2/scripts/eval_base/logs
+ bash /home/x-qlan1/code/moule2/scripts/eval_base/sh/eval_aime25.sh
+ source /anvil/scratch/x-qlan1/moule/train-env/bin/activate
++ '[' -z '' ']'
++ '[' -n x ']'
++ SCRIPT_PATH=/anvil/scratch/x-qlan1/moule/train-env/bin/activate
++ '[' /anvil/scratch/x-qlan1/moule/train-env/bin/activate = /home/x-qlan1/code/moule2/scripts/eval_base/sh/eval_aime25.sh ']'
++ deactivate nondestructive
++ unset -f pydoc
++ '[' -z '' ']'
++ '[' -z '' ']'
++ hash -r
++ '[' -z '' ']'
++ unset VIRTUAL_ENV
++ unset VIRTUAL_ENV_PROMPT
++ '[' '!' nondestructive = nondestructive ']'
++ VIRTUAL_ENV=/anvil/scratch/x-qlan1/moule/train-env
++ '[' linux-gnu = cygwin ']'
++ '[' linux-gnu = msys ']'
++ export VIRTUAL_ENV
++ '[' -z '' ']'
++ unset SCRIPT_PATH
++ _OLD_VIRTUAL_PATH=/anvil/scratch/x-qlan1/moule/train-env/bin:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/home/x-qlan1/.vscode-server/cli/servers/Stable-072586267e68ece9a47aa43f8c108e0dcbf44622/server/bin/remote-cli:/home/x-qlan1/miniconda3/bin:/home/x-qlan1/miniconda3/condabin:/apps/anvil/external/apps/xalt2/xalt/xalt/bin:/apps/spack/anvil/apps/openmpi/4.0.6-gcc-11.2.0-3navcwb/bin:/apps/spack/anvil/apps/numactl/2.0.14-gcc-11.2.0-wrjotmv/bin:/apps/spack/anvil/apps/libfabric/1.12.0-gcc-8.4.1-xj6lmd4/bin:/apps/spack/anvil/apps/gcc/11.2.0-gcc-8.4.1-qjtdkvs/bin:/home/x-qlan1/bin:/home/x-qlan1/.local/bin:/usr/libexec/gsissh/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/usr/site/rcac/sbin:/usr/site/rcac/bin:/usr/site/rcac/scripts:/opt/thinlinc/bin:/opt/thinlinc/sbin:/home/x-qlan1/.vscode-server/extensions/ms-python.debugpy-2025.18.0-linux-x64/bundled/scripts/noConfigScripts
++ PATH=/anvil/scratch/x-qlan1/moule/train-env/bin:/anvil/scratch/x-qlan1/moule/train-env/bin:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/debugCommand:/home/x-qlan1/.vscode-server/data/User/globalStorage/github.copilot-chat/copilotCli:/home/x-qlan1/.vscode-server/cli/servers/Stable-072586267e68ece9a47aa43f8c108e0dcbf44622/server/bin/remote-cli:/home/x-qlan1/miniconda3/bin:/home/x-qlan1/miniconda3/condabin:/apps/anvil/external/apps/xalt2/xalt/xalt/bin:/apps/spack/anvil/apps/openmpi/4.0.6-gcc-11.2.0-3navcwb/bin:/apps/spack/anvil/apps/numactl/2.0.14-gcc-11.2.0-wrjotmv/bin:/apps/spack/anvil/apps/libfabric/1.12.0-gcc-8.4.1-xj6lmd4/bin:/apps/spack/anvil/apps/gcc/11.2.0-gcc-8.4.1-qjtdkvs/bin:/home/x-qlan1/bin:/home/x-qlan1/.local/bin:/usr/libexec/gsissh/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/puppetlabs/bin:/usr/site/rcac/sbin:/usr/site/rcac/bin:/usr/site/rcac/scripts:/opt/thinlinc/bin:/opt/thinlinc/sbin:/home/x-qlan1/.vscode-server/extensions/ms-python.debugpy-2025.18.0-linux-x64/bundled/scripts/noConfigScripts
++ export PATH
++ '[' x '!=' x ']'
+++ basename /anvil/scratch/x-qlan1/moule/train-env
++ VIRTUAL_ENV_PROMPT=train-env
++ export VIRTUAL_ENV_PROMPT
++ '[' -z '' ']'
++ '[' -z '' ']'
++ _OLD_VIRTUAL_PS1=
++ PS1='(train-env) '
++ export PS1
++ alias pydoc
++ true
++ hash -r
+ SCRATCH=/anvil/scratch/x-qlan1/moule2
+ SCRIPT_DIR=/home/x-qlan1/code/moule2/scripts/eval_base/py
+ export HF_HOME=/anvil/scratch/x-qlan1/moule2/hf_cache
+ HF_HOME=/anvil/scratch/x-qlan1/moule2/hf_cache
+ export HF_DATASETS_CACHE=/anvil/scratch/x-qlan1/moule2/hf_cache/datasets
+ HF_DATASETS_CACHE=/anvil/scratch/x-qlan1/moule2/hf_cache/datasets
+ export TRANSFORMERS_CACHE=/anvil/scratch/x-qlan1/moule2/hf_cache
+ TRANSFORMERS_CACHE=/anvil/scratch/x-qlan1/moule2/hf_cache
+ export TORCH_HOME=/anvil/scratch/x-qlan1/moule2/torch_cache
+ TORCH_HOME=/anvil/scratch/x-qlan1/moule2/torch_cache
+ export LD_PRELOAD=/home/x-qlan1/miniconda3/lib/libstdc++.so.6
+ LD_PRELOAD=/home/x-qlan1/miniconda3/lib/libstdc++.so.6
+ OUTPUT_DIR=/anvil/scratch/x-qlan1/moule2/eval_results/base
+ mkdir -p /anvil/scratch/x-qlan1/moule2/eval_results/base
+ wait
+ run_model 2,3 Qwen/Qwen3-4B
+ local GPUS=2,3
+ local MODEL=Qwen/Qwen3-4B
+ echo ============================================================
+ echo '[2,3] Evaluating: Qwen/Qwen3-4B on AIME 2025'
+ echo ============================================================
+ CUDA_VISIBLE_DEVICES=2,3
+ python3 /home/x-qlan1/code/moule2/scripts/eval_base/py/eval_aime25.py --model Qwen/Qwen3-4B --mode greedy --max_tokens 38000 --max_model_len 40960 --tp 2 --gpu_memory_utilization 0.9 --output_dir /anvil/scratch/x-qlan1/moule2/eval_results/base
+ run_model 0,1 Qwen/Qwen3-1.7B
+ local GPUS=0,1
+ local MODEL=Qwen/Qwen3-1.7B
+ echo ============================================================
+ echo '[0,1] Evaluating: Qwen/Qwen3-1.7B on AIME 2025'
+ echo ============================================================
+ CUDA_VISIBLE_DEVICES=0,1
+ python3 /home/x-qlan1/code/moule2/scripts/eval_base/py/eval_aime25.py --model Qwen/Qwen3-1.7B --mode greedy --max_tokens 38000 --max_model_len 40960 --tp 2 --gpu_memory_utilization 0.9 --output_dir /anvil/scratch/x-qlan1/moule2/eval_results/base
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
`torch_dtype` is deprecated! Use `dtype` instead!
`torch_dtype` is deprecated! Use `dtype` instead!
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
W0226 19:25:50.214000 3174183 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:25:50.214000 3174183 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 19:25:50.214000 3174181 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:25:50.214000 3174181 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 19:25:50.215000 3174184 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:25:50.215000 3174184 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 19:25:50.215000 3174182 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:25:50.215000 3174182 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(Worker_TP0 pid=3174181)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(Worker_TP0 pid=3174182)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(Worker_TP0 pid=3174182)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.38s/it]
[1;36m(Worker_TP0 pid=3174182)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:06<00:00,  3.38s/it]
[1;36m(Worker_TP0 pid=3174182)[0;0m 
[1;36m(Worker_TP0 pid=3174181)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:07<00:14,  7.34s/it]
[1;36m(Worker_TP0 pid=3174181)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:07<00:03,  3.20s/it]
[1;36m(Worker_TP0 pid=3174181)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:17<00:00,  6.19s/it]
[1;36m(Worker_TP0 pid=3174181)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:17<00:00,  5.80s/it]
[1;36m(Worker_TP0 pid=3174181)[0;0m 
[1;36m(Worker_TP0 pid=3174182)[0;0m 2026-02-26 19:26:54,361 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP1 pid=3174184)[0;0m 2026-02-26 19:26:54,362 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP1 pid=3174184)[0;0m 2026-02-26 19:26:54,453 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3174182)[0;0m 2026-02-26 19:26:54,455 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3174182)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:12,  5.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–Ž         | 2/67 [00:00<00:10,  6.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:09,  6.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 4/67 [00:00<00:08,  7.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:08,  7.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:00<00:08,  6.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:01<00:08,  7.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 8/67 [00:01<00:08,  7.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:08,  7.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:01<00:08,  6.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:01<00:08,  6.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:01<00:08,  6.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–‰        | 13/67 [00:01<00:07,  6.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆ        | 14/67 [00:02<00:07,  6.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:02<00:07,  6.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 16/67 [00:02<00:07,  6.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:02<00:07,  6.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:02<00:07,  6.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:02<00:06,  6.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:02<00:07,  6.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:03<00:06,  6.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:03<00:07,  6.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:03<00:06,  6.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:03<00:06,  6.45it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:03<00:06,  6.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:03<00:06,  6.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:04<00:05,  6.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:04<00:05,  6.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:04<00:06,  6.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:04<00:05,  6.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:04<00:05,  6.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:04<00:05,  6.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:04<00:05,  6.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:05<00:05,  6.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:05<00:05,  5.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:05<00:05,  6.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:05<00:05,  5.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:05<00:04,  5.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:06<00:04,  5.83it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:06<00:04,  5.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:06<00:04,  5.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:06<00:04,  5.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:06<00:04,  5.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:06<00:04,  5.50it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:07<00:04,  5.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:07<00:03,  5.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:07<00:04,  4.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:07<00:04,  4.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:08<00:04,  4.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:08<00:03,  4.48it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:08<00:03,  4.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:08<00:03,  4.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:08<00:02,  4.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:09<00:02,  4.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:09<00:02,  5.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:09<00:02,  5.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:09<00:01,  5.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:09<00:01,  4.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:10<00:01,  5.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:10<00:01,  5.25it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:10<00:01,  5.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:10<00:00,  5.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:10<00:00,  5.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:10<00:00,  5.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:11<00:00,  5.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:11<00:00,  5.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:11<00:00,  5.47it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:11<00:00,  5.81it/s]
[1;36m(Worker_TP0 pid=3174182)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   1%|â–         | 1/67 [00:00<00:11,  5.89it/s]Capturing CUDA graphs (decode, FULL):   3%|â–Ž         | 2/67 [00:00<00:09,  6.82it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 3/67 [00:00<00:08,  7.65it/s]Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 4/67 [00:00<00:08,  7.75it/s]Capturing CUDA graphs (decode, FULL):   7%|â–‹         | 5/67 [00:00<00:08,  7.67it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:00<00:07,  7.83it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 7/67 [00:00<00:07,  7.93it/s]Capturing CUDA graphs (decode, FULL):  12%|â–ˆâ–        | 8/67 [00:01<00:07,  7.98it/s]Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:07,  7.95it/s]Capturing CUDA graphs (decode, FULL):  15%|â–ˆâ–        | 10/67 [00:01<00:07,  7.98it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–‹        | 11/67 [00:01<00:07,  7.97it/s]Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 12/67 [00:01<00:06,  8.14it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:01<00:06,  8.01it/s]Capturing CUDA graphs (decode, FULL):  21%|â–ˆâ–ˆ        | 14/67 [00:01<00:06,  8.14it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 15/67 [00:01<00:06,  8.40it/s]Capturing CUDA graphs (decode, FULL):  24%|â–ˆâ–ˆâ–       | 16/67 [00:02<00:06,  8.27it/s]Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:02<00:06,  8.01it/s]Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:02<00:06,  8.02it/s][1;36m(Worker_TP1 pid=3174183)[0;0m 2026-02-26 19:27:10,111 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP0 pid=3174181)[0;0m 2026-02-26 19:27:10,117 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
Capturing CUDA graphs (decode, FULL):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:02<00:05,  8.09it/s][1;36m(Worker_TP0 pid=3174181)[0;0m 2026-02-26 19:27:10,269 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:02<00:05,  8.32it/s][1;36m(Worker_TP1 pid=3174183)[0;0m 2026-02-26 19:27:10,283 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:02<00:06,  7.37it/s]Capturing CUDA graphs (decode, FULL):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:02<00:05,  7.56it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:02<00:05,  7.45it/s]Capturing CUDA graphs (decode, FULL):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:03<00:05,  7.49it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:03<00:05,  7.28it/s]Capturing CUDA graphs (decode, FULL):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:03<00:05,  7.39it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:03<00:05,  7.40it/s]Capturing CUDA graphs (decode, FULL):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:03<00:05,  7.33it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:03<00:05,  7.49it/s]Capturing CUDA graphs (decode, FULL):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:03<00:04,  7.49it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:04<00:04,  7.57it/s]Capturing CUDA graphs (decode, FULL):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:04<00:04,  7.70it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:04<00:04,  7.71it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:04<00:04,  7.66it/s][1;36m(Worker_TP0 pid=3174181)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:04<00:04,  7.87it/s]Capturing CUDA graphs (decode, FULL):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:04<00:03,  7.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:16,  4.10it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:04<00:03,  8.02it/s]Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:04<00:03,  8.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–Ž         | 2/67 [00:00<00:13,  4.70it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:04<00:03,  8.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:12,  5.09it/s]Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:05<00:03,  8.13it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:05<00:03,  8.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 4/67 [00:00<00:12,  5.15it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:05<00:03,  8.33it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:05<00:02,  8.51it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:01<00:12,  4.82it/s]Capturing CUDA graphs (decode, FULL):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:05<00:02,  8.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:01<00:12,  4.90it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:05<00:02,  8.38it/s]Capturing CUDA graphs (decode, FULL):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:05<00:02,  8.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:01<00:12,  4.92it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:05<00:02,  8.31it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:06<00:02,  8.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 8/67 [00:01<00:12,  4.71it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:06<00:02,  8.43it/s]Capturing CUDA graphs (decode, FULL):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:06<00:02,  8.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:12,  4.79it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:06<00:01,  8.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:02<00:11,  4.76it/s]Capturing CUDA graphs (decode, FULL):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:06<00:01,  8.26it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:06<00:01,  8.44it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:02<00:11,  4.93it/s]Capturing CUDA graphs (decode, FULL):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:06<00:01,  8.48it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:06<00:01,  8.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:02<00:11,  4.93it/s]Capturing CUDA graphs (decode, FULL):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:07<00:01,  8.55it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–‰        | 13/67 [00:02<00:10,  4.96it/s]Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:07<00:01,  8.26it/s]Capturing CUDA graphs (decode, FULL):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:07<00:01,  8.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆ        | 14/67 [00:02<00:11,  4.72it/s]Capturing CUDA graphs (decode, FULL):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:07<00:00,  8.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:03<00:11,  4.58it/s]Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:07<00:00,  8.62it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:07<00:00,  8.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 16/67 [00:03<00:10,  4.72it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:07<00:00,  8.59it/s]Capturing CUDA graphs (decode, FULL):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:07<00:00,  8.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:03<00:10,  4.56it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:08<00:00,  8.40it/s]Capturing CUDA graphs (decode, FULL):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:08<00:00,  8.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:03<00:10,  4.66it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:08<00:00,  8.06it/s]
Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:03<00:10,  4.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:04<00:10,  4.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:04<00:10,  4.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:04<00:10,  4.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:04<00:10,  4.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:05<00:10,  4.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:05<00:10,  4.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:05<00:10,  4.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:05<00:09,  4.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:06<00:09,  4.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:06<00:09,  4.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:06<00:09,  4.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:06<00:08,  4.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:07<00:08,  4.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:07<00:08,  3.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:07<00:08,  4.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:07<00:07,  4.08it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:08<00:07,  4.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:08<00:07,  4.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:08<00:07,  3.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:08<00:07,  3.96it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:09<00:06,  4.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:09<00:06,  3.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:09<00:06,  3.94it/s]Adding requests:   0%|          | 0/30 [00:00<?, ?it/s]Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 87.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:09<00:06,  3.76it/s]Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 76.08it/s]Adding requests:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [00:00<00:00, 77.21it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 80.68it/s]
Processed prompts:   0%|          | 0/30 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:10<00:06,  3.61it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:10<00:06,  3.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:10<00:05,  3.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:11<00:05,  3.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:11<00:04,  3.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:11<00:04,  3.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:11<00:04,  3.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:12<00:04,  3.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:12<00:03,  3.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:12<00:03,  3.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:12<00:03,  3.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:13<00:03,  3.69it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:13<00:03,  3.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:13<00:02,  3.71it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:14<00:02,  3.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:14<00:02,  3.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:14<00:01,  3.67it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:14<00:01,  3.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:15<00:01,  3.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:15<00:01,  3.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:15<00:00,  3.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:15<00:00,  4.01it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:16<00:00,  4.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:16<00:00,  3.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:16<00:00,  4.10it/s]
[1;36m(Worker_TP0 pid=3174181)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   1%|â–         | 1/67 [00:00<00:13,  4.90it/s]Capturing CUDA graphs (decode, FULL):   3%|â–Ž         | 2/67 [00:00<00:12,  5.36it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 3/67 [00:00<00:10,  5.94it/s]Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 4/67 [00:00<00:10,  5.93it/s]Capturing CUDA graphs (decode, FULL):   7%|â–‹         | 5/67 [00:00<00:09,  6.27it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:01<00:10,  6.10it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 7/67 [00:01<00:09,  6.28it/s]Capturing CUDA graphs (decode, FULL):  12%|â–ˆâ–        | 8/67 [00:01<00:09,  6.21it/s]Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:09,  6.25it/s]Capturing CUDA graphs (decode, FULL):  15%|â–ˆâ–        | 10/67 [00:01<00:09,  6.11it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–‹        | 11/67 [00:01<00:08,  6.38it/s]Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 12/67 [00:01<00:08,  6.30it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:02<00:08,  6.11it/s]Capturing CUDA graphs (decode, FULL):  21%|â–ˆâ–ˆ        | 14/67 [00:02<00:08,  6.10it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 15/67 [00:02<00:08,  6.18it/s]Capturing CUDA graphs (decode, FULL):  24%|â–ˆâ–ˆâ–       | 16/67 [00:02<00:08,  6.17it/s]Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:02<00:07,  6.36it/s]Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:02<00:08,  6.12it/s]Capturing CUDA graphs (decode, FULL):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:03<00:07,  6.22it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:03<00:07,  6.19it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:03<00:07,  6.29it/s]Capturing CUDA graphs (decode, FULL):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:03<00:07,  6.35it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:03<00:07,  6.18it/s]Capturing CUDA graphs (decode, FULL):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:03<00:06,  6.20it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:04<00:06,  6.15it/s]Capturing CUDA graphs (decode, FULL):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:04<00:06,  6.12it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:04<00:06,  6.09it/s]Capturing CUDA graphs (decode, FULL):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:04<00:06,  6.13it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:04<00:06,  6.20it/s]Capturing CUDA graphs (decode, FULL):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:04<00:05,  6.32it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:05<00:05,  6.27it/s]Capturing CUDA graphs (decode, FULL):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:05<00:05,  6.31it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:05<00:05,  6.11it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:05<00:05,  6.17it/s]Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:05<00:05,  6.11it/s]Capturing CUDA graphs (decode, FULL):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:05<00:05,  6.06it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:06<00:04,  6.24it/s]Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:06<00:04,  5.93it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:06<00:04,  6.16it/s]Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:06<00:04,  6.07it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:06<00:04,  6.19it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:06<00:04,  6.00it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:06<00:03,  6.15it/s]Capturing CUDA graphs (decode, FULL):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:07<00:03,  6.19it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:07<00:03,  6.08it/s]Capturing CUDA graphs (decode, FULL):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:07<00:03,  6.21it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:07<00:03,  6.10it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:07<00:03,  6.01it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:07<00:02,  6.06it/s]Capturing CUDA graphs (decode, FULL):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:08<00:02,  6.16it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:08<00:02,  6.02it/s]Capturing CUDA graphs (decode, FULL):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:08<00:02,  6.22it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:08<00:02,  6.12it/s]Capturing CUDA graphs (decode, FULL):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:08<00:02,  6.15it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:08<00:01,  6.36it/s]Capturing CUDA graphs (decode, FULL):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:09<00:01,  6.28it/s]Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:09<00:01,  6.06it/s]Capturing CUDA graphs (decode, FULL):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:09<00:01,  6.25it/s]Capturing CUDA graphs (decode, FULL):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:09<00:01,  6.11it/s]Capturing CUDA graphs (decode, FULL):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:09<00:01,  6.07it/s]Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:09<00:00,  6.11it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:10<00:00,  6.29it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:10<00:00,  5.96it/s]Capturing CUDA graphs (decode, FULL):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:10<00:00,  6.17it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:10<00:00,  6.21it/s]Capturing CUDA graphs (decode, FULL):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:10<00:00,  6.17it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:10<00:00,  6.05it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:10<00:00,  6.14it/s]
Adding requests:   0%|          | 0/30 [00:00<?, ?it/s]Adding requests:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [00:00<00:00, 103.76it/s]Adding requests:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [00:00<00:00, 80.84it/s] Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 87.06it/s]
Processed prompts:   0%|          | 0/30 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|â–Ž         | 1/30 [00:44<21:32, 44.56s/it, est. speed input: 23.99 toks/s, output: 57.12 toks/s]Processed prompts:   3%|â–Ž         | 1/30 [00:38<18:25, 38.12s/it, est. speed input: 28.05 toks/s, output: 60.76 toks/s]Processed prompts:   7%|â–‹         | 2/30 [01:07<14:53, 31.90s/it, est. speed input: 32.41 toks/s, output: 96.87 toks/s]Processed prompts:   7%|â–‹         | 2/30 [01:11<16:29, 35.34s/it, est. speed input: 30.64 toks/s, output: 86.44 toks/s]Processed prompts:  10%|â–ˆ         | 3/30 [01:35<13:33, 30.14s/it, est. speed input: 34.91 toks/s, output: 124.20 toks/s]Processed prompts:  10%|â–ˆ         | 3/30 [01:25<11:34, 25.71s/it, est. speed input: 38.08 toks/s, output: 124.49 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 5/30 [01:44<06:54, 16.59s/it, est. speed input: 52.83 toks/s, output: 196.08 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 6/30 [01:47<05:03, 12.65s/it, est. speed input: 62.79 toks/s, output: 242.08 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 4/30 [02:16<14:52, 34.35s/it, est. speed input: 32.95 toks/s, output: 140.54 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 5/30 [02:20<09:41, 23.28s/it, est. speed input: 40.42 toks/s, output: 189.98 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 6/30 [02:21<06:22, 15.93s/it, est. speed input: 47.52 toks/s, output: 240.70 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:39<06:23, 16.67s/it, est. speed input: 48.94 toks/s, output: 264.87 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 8/30 [02:41<04:17, 11.70s/it, est. speed input: 55.73 toks/s, output: 314.58 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:27<07:52, 20.55s/it, est. speed input: 53.28 toks/s, output: 224.73 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 8/30 [02:40<06:43, 18.35s/it, est. speed input: 56.09 toks/s, output: 253.68 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [03:11<06:07, 17.52s/it, est. speed input: 53.06 toks/s, output: 314.63 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [02:53<05:53, 16.83s/it, est. speed input: 59.06 toks/s, output: 281.10 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:03<04:54, 14.75s/it, est. speed input: 61.95 toks/s, output: 312.47 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [03:45<07:33, 22.67s/it, est. speed input: 50.68 toks/s, output: 315.73 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:46<05:03, 15.99s/it, est. speed input: 55.50 toks/s, output: 363.30 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:54<08:02, 25.38s/it, est. speed input: 53.32 toks/s, output: 290.28 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:20<06:27, 21.54s/it, est. speed input: 52.54 toks/s, output: 363.65 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [04:04<06:14, 20.82s/it, est. speed input: 56.26 toks/s, output: 323.54 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:10<04:39, 16.43s/it, est. speed input: 59.24 toks/s, output: 360.98 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [04:42<06:09, 21.74s/it, est. speed input: 52.28 toks/s, output: 383.21 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [04:21<03:55, 14.75s/it, est. speed input: 61.11 toks/s, output: 391.14 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [04:49<04:35, 17.20s/it, est. speed input: 54.93 toks/s, output: 422.43 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:33<06:21, 25.42s/it, est. speed input: 51.01 toks/s, output: 413.55 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [05:38<04:28, 19.20s/it, est. speed input: 53.61 toks/s, output: 455.04 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [05:20<07:03, 28.23s/it, est. speed input: 53.25 toks/s, output: 362.78 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [05:55<03:58, 18.37s/it, est. speed input: 54.25 toks/s, output: 481.67 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [05:37<05:44, 24.63s/it, est. speed input: 53.97 toks/s, output: 390.19 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:06<03:15, 16.30s/it, est. speed input: 55.59 toks/s, output: 514.37 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [06:12<02:24, 13.15s/it, est. speed input: 57.85 toks/s, output: 554.09 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [06:12<01:32,  9.24s/it, est. speed input: 60.81 toks/s, output: 601.59 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:00<05:14, 24.19s/it, est. speed input: 53.78 toks/s, output: 409.83 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [06:26<01:36, 10.71s/it, est. speed input: 61.85 toks/s, output: 627.44 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:20<04:35, 22.93s/it, est. speed input: 54.26 toks/s, output: 432.72 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [06:50<01:57, 14.73s/it, est. speed input: 61.23 toks/s, output: 638.23 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [07:00<01:32, 13.23s/it, est. speed input: 62.53 toks/s, output: 670.99 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [07:01<00:57,  9.64s/it, est. speed input: 65.32 toks/s, output: 716.49 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [06:52<04:41, 25.57s/it, est. speed input: 52.86 toks/s, output: 443.62 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [07:22<01:04, 12.81s/it, est. speed input: 64.83 toks/s, output: 731.56 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [07:06<03:43, 22.31s/it, est. speed input: 53.71 toks/s, output: 472.44 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [07:33<00:49, 12.37s/it, est. speed input: 66.06 toks/s, output: 761.05 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 27/30 [08:51<01:36, 32.09s/it, est. speed input: 58.72 toks/s, output: 697.25 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [08:30<06:07, 40.83s/it, est. speed input: 47.40 toks/s, output: 438.19 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:47<04:29, 33.73s/it, est. speed input: 48.20 toks/s, output: 467.38 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [09:23<01:03, 31.97s/it, est. speed input: 57.44 toks/s, output: 706.63 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [09:05<03:21, 28.79s/it, est. speed input: 48.71 toks/s, output: 496.02 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 29/30 [12:43<01:22, 82.51s/it, est. speed input: 43.80 toks/s, output: 570.90 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [12:43<00:00, 82.51s/it, est. speed input: 45.40 toks/s, output: 620.63 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [12:43<00:00, 25.46s/it, est. speed input: 45.40 toks/s, output: 620.63 toks/s]
+ CUDA_VISIBLE_DEVICES=0,1
+ python3 /home/x-qlan1/code/moule2/scripts/eval_base/py/eval_aime25.py --model Qwen/Qwen3-1.7B --mode average --n_samples 16 --temperature 1.2 --top_p 0.95 --max_tokens 38000 --max_model_len 40960 --tp 2 --gpu_memory_utilization 0.9 --output_dir /anvil/scratch/x-qlan1/moule2/eval_results/base
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
`torch_dtype` is deprecated! Use `dtype` instead!
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [13:49<10:32, 105.38s/it, est. speed input: 33.35 toks/s, output: 369.97 toks/s]/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [14:19<06:53, 82.72s/it, est. speed input: 33.54 toks/s, output: 401.34 toks/s] Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [14:19<00:00, 82.72s/it, est. speed input: 40.35 toks/s, output: 622.45 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [14:19<00:00, 28.64s/it, est. speed input: 40.35 toks/s, output: 622.45 toks/s]
+ CUDA_VISIBLE_DEVICES=2,3
+ python3 /home/x-qlan1/code/moule2/scripts/eval_base/py/eval_aime25.py --model Qwen/Qwen3-4B --mode average --n_samples 16 --temperature 1.2 --top_p 0.95 --max_tokens 38000 --max_model_len 40960 --tp 2 --gpu_memory_utilization 0.9 --output_dir /anvil/scratch/x-qlan1/moule2/eval_results/base
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
W0226 19:42:17.596000 3178021 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:42:17.596000 3178021 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 19:42:17.597000 3178020 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:42:17.597000 3178020 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[1;36m(Worker_TP0 pid=3178020)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]
[1;36m(Worker_TP0 pid=3178020)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:04<00:00,  2.26s/it]
[1;36m(Worker_TP0 pid=3178020)[0;0m Loading safetensors checkpoint shards: 100% Completed | 2/2 [00:04<00:00,  2.26s/it]
[1;36m(Worker_TP0 pid=3178020)[0;0m 
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
`torch_dtype` is deprecated! Use `dtype` instead!
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
[1;36m(Worker_TP0 pid=3178020)[0;0m 2026-02-26 19:43:04,594 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP1 pid=3178021)[0;0m 2026-02-26 19:43:04,596 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP0 pid=3178020)[0;0m 2026-02-26 19:43:04,678 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP1 pid=3178021)[0;0m 2026-02-26 19:43:04,680 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3178020)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:07,  8.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–Ž         | 2/67 [00:00<00:07,  9.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 4/67 [00:00<00:05, 11.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:00<00:06,  9.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:00<00:06,  9.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:06,  9.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:01<00:06,  9.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:01<00:06,  9.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:01<00:06,  8.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–‰        | 13/67 [00:01<00:06,  8.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆ        | 14/67 [00:01<00:05,  8.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 16/67 [00:01<00:05,  9.04it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:01<00:05,  8.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:01<00:05,  8.38it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:02<00:05,  8.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:02<00:05,  8.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:02<00:04,  9.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:02<00:04,  9.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:02<00:04,  9.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:02<00:04,  9.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:03<00:04,  9.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:03<00:04,  8.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:03<00:04,  8.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:03<00:04,  8.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:03<00:04,  8.72it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:03<00:04,  8.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:03<00:03,  8.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:03<00:03,  8.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:04<00:03,  8.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:04<00:03,  8.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:04<00:03,  8.43it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:04<00:03,  8.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:04<00:03,  8.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:04<00:02,  8.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:04<00:02,  8.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:04<00:02,  8.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:05<00:02,  8.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:05<00:02,  8.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:05<00:02,  8.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:05<00:02,  7.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:05<00:02,  7.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:05<00:02,  7.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:05<00:01,  8.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:05<00:01,  7.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:06<00:01,  8.33it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:06<00:01,  8.39it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:06<00:01,  8.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:06<00:01,  8.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:06<00:01,  8.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:06<00:01,  7.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:06<00:01,  7.62it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:06<00:00,  7.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:07<00:00,  7.54it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:07<00:00,  7.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:07<00:00,  7.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:07<00:00,  8.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  9.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  8.61it/s]
[1;36m(Worker_TP0 pid=3178020)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   1%|â–         | 1/67 [00:00<00:09,  6.62it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 3/67 [00:00<00:21,  3.00it/s]Capturing CUDA graphs (decode, FULL):   7%|â–‹         | 5/67 [00:01<00:12,  5.16it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 7/67 [00:01<00:08,  6.82it/s]Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:07,  8.13it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–‹        | 11/67 [00:01<00:05,  9.38it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:01<00:05, 10.25it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 15/67 [00:01<00:05, 10.17it/s]Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:02<00:04, 10.23it/s]Capturing CUDA graphs (decode, FULL):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:02<00:04, 10.86it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:02<00:04, 11.06it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:02<00:04, 10.45it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:02<00:03, 11.19it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:02<00:03, 11.46it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:03<00:03, 11.81it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:03<00:02, 12.36it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:03<00:02, 12.39it/s]Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:03<00:02, 12.11it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:03<00:02, 11.81it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:03<00:02, 11.35it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:04<00:02, 10.88it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:04<00:02, 10.83it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:04<00:02, 10.78it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:04<00:01, 10.93it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:04<00:01, 11.39it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:05<00:01, 11.79it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:05<00:01, 12.30it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:05<00:01, 11.64it/s]Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:05<00:00, 10.49it/s]Capturing CUDA graphs (decode, FULL):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:05<00:00, 10.02it/s]Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:05<00:00, 10.65it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:06<00:00, 11.02it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:06<00:00, 11.52it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:06<00:00, 12.14it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:06<00:00, 10.37it/s]
Adding requests:   0%|          | 0/30 [00:00<?, ?it/s]Adding requests:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [00:00<00:00, 89.58it/s]Adding requests:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [00:00<00:00, 66.03it/s]Adding requests:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [00:00<00:00, 66.79it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 66.76it/s]
Processed prompts:   0%|          | 0/480 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
W0226 19:44:06.987000 3178980 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:44:06.987000 3178980 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 19:44:06.988000 3178979 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 19:44:06.988000 3178979 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(Worker_TP0 pid=3178979)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/3 [00:00<?, ?it/s]
[1;36m(Worker_TP0 pid=3178979)[0;0m Loading safetensors checkpoint shards:  33% Completed | 1/3 [00:09<00:19,  9.93s/it]
[1;36m(Worker_TP0 pid=3178979)[0;0m Loading safetensors checkpoint shards:  67% Completed | 2/3 [00:10<00:04,  4.31s/it]
[1;36m(Worker_TP0 pid=3178979)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:20<00:00,  7.05s/it]
[1;36m(Worker_TP0 pid=3178979)[0;0m Loading safetensors checkpoint shards: 100% Completed | 3/3 [00:20<00:00,  6.87s/it]
[1;36m(Worker_TP0 pid=3178979)[0;0m 
[1;36m(Worker_TP0 pid=3178979)[0;0m 2026-02-26 19:45:37,886 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP1 pid=3178980)[0;0m 2026-02-26 19:45:37,887 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP1 pid=3178980)[0;0m 2026-02-26 19:45:38,047 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3178979)[0;0m 2026-02-26 19:45:38,050 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3178979)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:17,  3.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|â–Ž         | 2/67 [00:00<00:14,  4.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:13,  4.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|â–Œ         | 4/67 [00:00<00:12,  5.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:01<00:13,  4.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|â–‰         | 6/67 [00:01<00:12,  4.78it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:01<00:12,  4.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|â–ˆâ–        | 8/67 [00:01<00:12,  4.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:12,  4.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|â–ˆâ–        | 10/67 [00:02<00:12,  4.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:02<00:12,  4.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|â–ˆâ–Š        | 12/67 [00:02<00:11,  4.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–‰        | 13/67 [00:02<00:10,  4.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|â–ˆâ–ˆ        | 14/67 [00:02<00:11,  4.60it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:03<00:11,  4.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|â–ˆâ–ˆâ–       | 16/67 [00:03<00:11,  4.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:03<00:11,  4.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:03<00:10,  4.53it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:04<00:10,  4.50it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:04<00:10,  4.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:04<00:10,  4.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:04<00:09,  4.52it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:04<00:10,  4.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:05<00:09,  4.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:05<00:09,  4.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:05<00:09,  4.22it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:05<00:09,  4.25it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:06<00:09,  4.29it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:06<00:09,  4.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:06<00:08,  4.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:06<00:08,  4.10it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:07<00:08,  4.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:07<00:08,  3.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:07<00:08,  3.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:07<00:08,  3.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:08<00:07,  3.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:08<00:07,  3.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:08<00:07,  3.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:08<00:07,  3.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:09<00:07,  3.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:09<00:06,  3.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:09<00:06,  3.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:10<00:06,  3.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:10<00:05,  3.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:10<00:05,  3.84it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:10<00:05,  3.88it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:11<00:05,  3.80it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:11<00:04,  3.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:11<00:04,  3.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:11<00:04,  3.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:12<00:04,  3.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:12<00:03,  3.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:12<00:03,  3.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:12<00:03,  3.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:13<00:03,  3.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:13<00:03,  3.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:13<00:02,  3.58it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:14<00:02,  3.70it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:14<00:02,  3.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:14<00:01,  3.63it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:14<00:01,  3.69it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:15<00:01,  3.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:15<00:01,  3.73it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:15<00:00,  3.76it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:15<00:00,  3.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:16<00:00,  4.16it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:16<00:00,  3.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:16<00:00,  4.09it/s]
[1;36m(Worker_TP0 pid=3178979)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   1%|â–         | 1/67 [00:00<00:15,  4.40it/s]Capturing CUDA graphs (decode, FULL):   3%|â–Ž         | 2/67 [00:00<00:12,  5.24it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 3/67 [00:00<00:11,  5.54it/s]Capturing CUDA graphs (decode, FULL):   6%|â–Œ         | 4/67 [00:00<00:10,  5.94it/s]Capturing CUDA graphs (decode, FULL):   7%|â–‹         | 5/67 [00:00<00:10,  6.05it/s]Capturing CUDA graphs (decode, FULL):   9%|â–‰         | 6/67 [00:01<00:09,  6.10it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 7/67 [00:01<00:10,  5.91it/s]Capturing CUDA graphs (decode, FULL):  12%|â–ˆâ–        | 8/67 [00:01<00:09,  6.03it/s]Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:01<00:09,  6.09it/s]Capturing CUDA graphs (decode, FULL):  15%|â–ˆâ–        | 10/67 [00:01<00:09,  5.98it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–‹        | 11/67 [00:01<00:09,  6.19it/s]Capturing CUDA graphs (decode, FULL):  18%|â–ˆâ–Š        | 12/67 [00:02<00:08,  6.12it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:02<00:09,  5.99it/s]Capturing CUDA graphs (decode, FULL):  21%|â–ˆâ–ˆ        | 14/67 [00:02<00:08,  6.02it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 15/67 [00:02<00:08,  5.98it/s]Capturing CUDA graphs (decode, FULL):  24%|â–ˆâ–ˆâ–       | 16/67 [00:02<00:08,  6.07it/s]Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:02<00:08,  5.99it/s]Capturing CUDA graphs (decode, FULL):  27%|â–ˆâ–ˆâ–‹       | 18/67 [00:03<00:08,  6.12it/s]Capturing CUDA graphs (decode, FULL):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:03<00:08,  5.97it/s]Capturing CUDA graphs (decode, FULL):  30%|â–ˆâ–ˆâ–‰       | 20/67 [00:03<00:07,  6.05it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:03<00:07,  6.07it/s]Capturing CUDA graphs (decode, FULL):  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 22/67 [00:03<00:07,  6.00it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:03<00:07,  6.15it/s]Capturing CUDA graphs (decode, FULL):  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 24/67 [00:04<00:06,  6.18it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:04<00:06,  6.08it/s]Capturing CUDA graphs (decode, FULL):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:04<00:06,  6.08it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:04<00:06,  6.16it/s]Capturing CUDA graphs (decode, FULL):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:04<00:06,  5.94it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:04<00:06,  6.10it/s]Capturing CUDA graphs (decode, FULL):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:04<00:06,  6.13it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:05<00:05,  6.07it/s]Capturing CUDA graphs (decode, FULL):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:05<00:05,  6.07it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:05<00:05,  6.00it/s]Capturing CUDA graphs (decode, FULL):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:05<00:05,  5.97it/s]Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:05<00:05,  6.02it/s]Capturing CUDA graphs (decode, FULL):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:05<00:05,  5.98it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:06<00:04,  6.10it/s]Capturing CUDA graphs (decode, FULL):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:06<00:04,  5.92it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:06<00:04,  5.95it/s]Capturing CUDA graphs (decode, FULL):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:06<00:04,  6.03it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:06<00:04,  6.01it/s]Capturing CUDA graphs (decode, FULL):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:06<00:04,  5.98it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:07<00:03,  6.02it/s]Capturing CUDA graphs (decode, FULL):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:07<00:03,  6.07it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:07<00:03,  5.90it/s]Capturing CUDA graphs (decode, FULL):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:07<00:03,  5.88it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:07<00:03,  5.86it/s]Capturing CUDA graphs (decode, FULL):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:08<00:03,  5.90it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:08<00:03,  5.89it/s]Capturing CUDA graphs (decode, FULL):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:08<00:02,  5.89it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:08<00:02,  5.87it/s]Capturing CUDA graphs (decode, FULL):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:08<00:02,  5.84it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:08<00:02,  6.00it/s]Capturing CUDA graphs (decode, FULL):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:09<00:02,  5.82it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:09<00:02,  5.98it/s]Capturing CUDA graphs (decode, FULL):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:09<00:01,  5.90it/s]Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:09<00:01,  5.92it/s]Capturing CUDA graphs (decode, FULL):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:09<00:01,  5.87it/s]Capturing CUDA graphs (decode, FULL):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:09<00:01,  5.97it/s]Capturing CUDA graphs (decode, FULL):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:10<00:01,  5.96it/s]Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:10<00:01,  5.95it/s]Capturing CUDA graphs (decode, FULL):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:10<00:00,  6.04it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:10<00:00,  5.90it/s]Capturing CUDA graphs (decode, FULL):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:10<00:00,  5.84it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:10<00:00,  5.91it/s]Capturing CUDA graphs (decode, FULL):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:11<00:00,  5.98it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:11<00:00,  6.35it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:11<00:00,  5.99it/s]
Adding requests:   0%|          | 0/30 [00:00<?, ?it/s]Adding requests:  27%|â–ˆâ–ˆâ–‹       | 8/30 [00:00<00:00, 76.85it/s]Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:00<00:00, 55.36it/s]Adding requests:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [00:00<00:00, 56.09it/s]Adding requests:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 28/30 [00:00<00:00, 53.97it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 55.42it/s]
Processed prompts:   0%|          | 0/480 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|â–Ž         | 16/480 [05:22<2:35:42, 20.13s/it, est. speed input: 53.09 toks/s, output: 153.53 toks/s]Processed prompts:   7%|â–‹         | 32/480 [05:41<1:07:11,  9.00s/it, est. speed input: 100.47 toks/s, output: 346.87 toks/s]Processed prompts:  10%|â–ˆ         | 48/480 [06:34<46:05,  6.40s/it, est. speed input: 133.56 toks/s, output: 521.61 toks/s]  Processed prompts:   3%|â–Ž         | 16/480 [06:25<3:06:06, 24.07s/it, est. speed input: 44.42 toks/s, output: 147.48 toks/s]Processed prompts:   7%|â–‹         | 32/480 [08:17<1:44:44, 14.03s/it, est. speed input: 71.37 toks/s, output: 348.11 toks/s]Processed prompts:  10%|â–ˆ         | 48/480 [08:42<1:00:09,  8.36s/it, est. speed input: 101.31 toks/s, output: 585.41 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 64/480 [12:06<1:23:41, 12.07s/it, est. speed input: 97.21 toks/s, output: 404.77 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 64/480 [09:35<44:09,  6.37s/it, est. speed input: 123.13 toks/s, output: 664.89 toks/s]  Processed prompts:  17%|â–ˆâ–‹        | 80/480 [13:11<1:01:13,  9.18s/it, est. speed input: 111.32 toks/s, output: 528.46 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 80/480 [11:50<47:23,  7.11s/it, est. speed input: 126.34 toks/s, output: 796.84 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 96/480 [15:24<56:50,  8.88s/it, est. speed input: 115.73 toks/s, output: 649.09 toks/s]  Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [16:39<46:05,  7.51s/it, est. speed input: 125.55 toks/s, output: 801.39 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 96/480 [14:16<49:53,  7.80s/it, est. speed input: 125.54 toks/s, output: 874.91 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 128/480 [17:30<35:59,  6.14s/it, est. speed input: 136.45 toks/s, output: 973.53 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [17:40<24:43,  4.42s/it, est. speed input: 151.90 toks/s, output: 1145.16 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [18:20<20:21,  3.82s/it, est. speed input: 162.91 toks/s, output: 1270.89 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [18:22<13:41,  2.70s/it, est. speed input: 179.09 toks/s, output: 1564.41 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [16:15<47:05,  7.68s/it, est. speed input: 128.83 toks/s, output: 907.56 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [20:48<22:18,  4.65s/it, est. speed input: 174.05 toks/s, output: 1663.60 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [21:04<16:02,  3.54s/it, est. speed input: 186.37 toks/s, output: 1733.14 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 128/480 [18:36<47:06,  8.03s/it, est. speed input: 130.92 toks/s, output: 1082.76 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [19:27<36:31,  6.52s/it, est. speed input: 141.02 toks/s, output: 1237.46 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [23:27<22:04,  5.17s/it, est. speed input: 180.63 toks/s, output: 1767.92 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [23:44<15:43,  3.93s/it, est. speed input: 192.29 toks/s, output: 1835.85 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [25:54<19:23,  5.19s/it, est. speed input: 187.59 toks/s, output: 1849.06 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [28:07<21:14,  6.13s/it, est. speed input: 183.61 toks/s, output: 1941.90 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [28:34<15:22,  4.80s/it, est. speed input: 192.58 toks/s, output: 2064.20 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [29:22<12:29,  4.26s/it, est. speed input: 197.60 toks/s, output: 2121.13 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [29:27<08:10,  3.07s/it, est. speed input: 208.50 toks/s, output: 2279.69 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [30:02<06:45,  2.82s/it, est. speed input: 214.14 toks/s, output: 2416.38 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [27:23<1:12:59, 13.69s/it, est. speed input: 112.24 toks/s, output: 1186.35 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [28:12<52:53, 10.44s/it, est. speed input: 119.14 toks/s, output: 1192.59 toks/s]  Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [31:34<07:51,  3.68s/it, est. speed input: 214.74 toks/s, output: 2459.18 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [28:46<37:56,  7.90s/it, est. speed input: 127.36 toks/s, output: 1411.01 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [29:09<26:59,  5.95s/it, est. speed input: 136.12 toks/s, output: 1445.69 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [33:17<08:25,  4.51s/it, est. speed input: 212.66 toks/s, output: 2447.54 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [34:40<07:33,  4.72s/it, est. speed input: 213.81 toks/s, output: 2507.72 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [35:53<06:13,  4.66s/it, est. speed input: 214.83 toks/s, output: 2512.06 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [35:55<03:31,  3.31s/it, est. speed input: 222.87 toks/s, output: 2627.54 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [36:38<02:29,  3.12s/it, est. speed input: 226.46 toks/s, output: 2674.61 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [34:41<44:25, 10.41s/it, est. speed input: 123.23 toks/s, output: 1377.11 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [37:45<01:49,  3.43s/it, est. speed input: 227.79 toks/s, output: 2726.90 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [37:52<00:40,  2.55s/it, est. speed input: 235.22 toks/s, output: 2815.38 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [38:31<00:00,  2.51s/it, est. speed input: 239.98 toks/s, output: 2923.20 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [38:31<00:00,  2.51s/it, est. speed input: 239.98 toks/s, output: 2923.20 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [38:31<00:00,  4.82s/it, est. speed input: 239.98 toks/s, output: 2923.20 toks/s]
Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [36:06<35:33,  8.89s/it, est. speed input: 127.41 toks/s, output: 1386.97 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [36:47<26:02,  6.97s/it, est. speed input: 133.16 toks/s, output: 1518.59 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [40:07<29:58,  8.64s/it, est. speed input: 129.42 toks/s, output: 1521.86 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [41:38<24:48,  7.75s/it, est. speed input: 132.17 toks/s, output: 1628.29 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [44:21<24:53,  8.49s/it, est. speed input: 130.68 toks/s, output: 1644.25 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [47:04<23:57,  8.98s/it, est. speed input: 129.56 toks/s, output: 1622.37 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [48:49<19:50,  8.27s/it, est. speed input: 131.05 toks/s, output: 1629.75 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [49:56<15:00,  7.03s/it, est. speed input: 134.88 toks/s, output: 1713.56 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [53:13<16:06,  8.63s/it, est. speed input: 132.85 toks/s, output: 1726.87 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [54:35<12:07,  7.57s/it, est. speed input: 135.83 toks/s, output: 1788.97 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [55:09<07:55,  5.94s/it, est. speed input: 139.76 toks/s, output: 1828.05 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [57:04<06:43,  6.31s/it, est. speed input: 140.17 toks/s, output: 1843.36 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [58:26<04:45,  5.95s/it, est. speed input: 142.07 toks/s, output: 1881.20 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [1:00:18<03:20,  6.27s/it, est. speed input: 143.22 toks/s, output: 1881.99 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [1:01:08<01:25,  5.33s/it, est. speed input: 146.35 toks/s, output: 1957.27 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [1:02:33<00:00,  5.33s/it, est. speed input: 147.79 toks/s, output: 2014.37 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [1:02:33<00:00,  5.33s/it, est. speed input: 147.79 toks/s, output: 2014.37 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [1:02:33<00:00,  7.82s/it, est. speed input: 147.79 toks/s, output: 2014.37 toks/s]
+ run_model 0,1 Qwen/Qwen3-8B
+ local GPUS=0,1
+ local MODEL=Qwen/Qwen3-8B
+ echo ============================================================
+ echo '[0,1] Evaluating: Qwen/Qwen3-8B on AIME 2025'
+ echo ============================================================
+ CUDA_VISIBLE_DEVICES=0,1
+ python3 /home/x-qlan1/code/moule2/scripts/eval_base/py/eval_aime25.py --model Qwen/Qwen3-8B --mode greedy --max_tokens 38000 --max_model_len 40960 --tp 2 --gpu_memory_utilization 0.9 --output_dir /anvil/scratch/x-qlan1/moule2/eval_results/base
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
`torch_dtype` is deprecated! Use `dtype` instead!
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
W0226 20:50:08.702000 3192933 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 20:50:08.702000 3192933 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 20:50:08.703000 3192932 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 20:50:08.703000 3192932 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:01<00:04,  1.08s/it]
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:04<00:06,  2.28s/it]
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:08<00:05,  2.97s/it]
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:11<00:03,  3.29s/it]
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:15<00:00,  3.45s/it]
[1;36m(Worker_TP0 pid=3192932)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:15<00:00,  3.10s/it]
[1;36m(Worker_TP0 pid=3192932)[0;0m 
[1;36m(Worker_TP1 pid=3192933)[0;0m 2026-02-26 20:51:01,079 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP0 pid=3192932)[0;0m 2026-02-26 20:51:01,081 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP0 pid=3192932)[0;0m 2026-02-26 20:51:01,339 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP1 pid=3192933)[0;0m 2026-02-26 20:51:01,347 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3192932)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:08,  7.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:06,  9.98it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:06, 10.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:00<00:05, 10.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:05, 10.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:01<00:05, 10.31it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–‰        | 13/67 [00:01<00:05, 10.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:01<00:05,  9.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:01<00:04, 10.09it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:01<00:04, 10.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:02<00:04, 10.37it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:02<00:04, 10.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:02<00:04, 10.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:02<00:03, 10.03it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:02<00:03,  9.94it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:02<00:03,  9.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:03<00:03,  9.66it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:03<00:03,  9.44it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:03<00:03,  9.35it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:03<00:03,  9.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:03<00:03,  9.20it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:03<00:03,  9.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:03<00:03,  8.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:03<00:03,  8.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:04<00:03,  8.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:04<00:03,  8.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:04<00:02,  8.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:04<00:02,  8.65it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:04<00:02,  8.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:04<00:02,  9.12it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:04<00:02,  8.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:04<00:02,  8.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:05<00:02,  8.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:05<00:02,  8.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:05<00:01,  8.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:05<00:01,  8.40it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:05<00:01,  8.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:05<00:01,  7.57it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:05<00:01,  7.95it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:05<00:01,  7.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:06<00:01,  7.99it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:06<00:01,  8.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:06<00:01,  8.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:06<00:00,  8.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:06<00:00,  8.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:06<00:00,  8.14it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:06<00:00,  8.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:06<00:00,  8.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:06<00:00,  8.28it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:07<00:00,  8.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:07<00:00,  8.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  8.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  9.12it/s]
[1;36m(Worker_TP0 pid=3192932)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   1%|â–         | 1/67 [00:00<00:06,  9.57it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 3/67 [00:00<00:05, 12.05it/s]Capturing CUDA graphs (decode, FULL):   7%|â–‹         | 5/67 [00:00<00:05, 12.37it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 7/67 [00:00<00:04, 12.75it/s]Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:04, 12.64it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–‹        | 11/67 [00:00<00:04, 12.71it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:01<00:04, 12.68it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 15/67 [00:01<00:04, 12.66it/s]Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:01<00:03, 13.11it/s]Capturing CUDA graphs (decode, FULL):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:01<00:03, 13.02it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:01<00:03, 12.99it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:01<00:03, 13.04it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:01<00:03, 13.00it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:02<00:03, 13.02it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:02<00:02, 12.99it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:02<00:02, 12.98it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:02<00:02, 12.94it/s]Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:02<00:02, 13.11it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:02<00:02, 13.14it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:03<00:02, 13.07it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:03<00:01, 13.21it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:03<00:01, 13.20it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:03<00:01, 12.87it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:03<00:01, 13.12it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:03<00:01, 12.98it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:03<00:01, 13.19it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:04<00:01, 13.03it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:04<00:00, 12.87it/s]Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:04<00:00, 12.95it/s]Capturing CUDA graphs (decode, FULL):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:04<00:00, 13.06it/s]Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:04<00:00, 13.02it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:04<00:00, 13.01it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:05<00:00, 13.02it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:05<00:00, 13.23it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:05<00:00, 12.97it/s]
Adding requests:   0%|          | 0/30 [00:00<?, ?it/s]Adding requests:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [00:00<00:00, 155.20it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 144.84it/s]
Processed prompts:   0%|          | 0/30 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|â–Ž         | 1/30 [00:40<19:41, 40.76s/it, est. speed input: 26.23 toks/s, output: 68.28 toks/s]Processed prompts:   7%|â–‹         | 2/30 [01:25<20:03, 42.98s/it, est. speed input: 25.14 toks/s, output: 96.66 toks/s]Processed prompts:  10%|â–ˆ         | 3/30 [01:32<12:03, 26.78s/it, est. speed input: 35.20 toks/s, output: 152.25 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 4/30 [01:46<09:18, 21.49s/it, est. speed input: 42.32 toks/s, output: 195.76 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 5/30 [01:54<07:01, 16.84s/it, est. speed input: 49.12 toks/s, output: 243.21 toks/s]Processed prompts:  20%|â–ˆâ–ˆ        | 6/30 [02:08<06:18, 15.77s/it, est. speed input: 52.40 toks/s, output: 278.57 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 7/30 [02:24<06:06, 15.94s/it, est. speed input: 54.29 toks/s, output: 308.11 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 8/30 [02:41<05:54, 16.12s/it, est. speed input: 55.75 toks/s, output: 336.83 toks/s]Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 9/30 [02:47<04:36, 13.14s/it, est. speed input: 61.05 toks/s, output: 383.51 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 10/30 [02:59<04:13, 12.65s/it, est. speed input: 63.52 toks/s, output: 418.21 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [03:22<05:02, 15.92s/it, est. speed input: 61.91 toks/s, output: 428.45 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 12/30 [03:32<04:11, 13.96s/it, est. speed input: 64.70 toks/s, output: 467.39 toks/s]Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 13/30 [03:45<03:52, 13.65s/it, est. speed input: 66.16 toks/s, output: 498.10 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/30 [04:07<04:20, 16.26s/it, est. speed input: 65.37 toks/s, output: 510.15 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 15/30 [04:14<03:20, 13.37s/it, est. speed input: 68.15 toks/s, output: 553.54 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 16/30 [06:23<11:13, 48.14s/it, est. speed input: 48.18 toks/s, output: 422.00 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 17/30 [06:31<07:52, 36.37s/it, est. speed input: 49.89 toks/s, output: 466.94 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 18/30 [06:35<05:17, 26.43s/it, est. speed input: 52.24 toks/s, output: 517.63 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 19/30 [06:43<03:50, 20.97s/it, est. speed input: 54.30 toks/s, output: 561.52 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 20/30 [06:53<02:55, 17.52s/it, est. speed input: 55.75 toks/s, output: 603.04 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [08:00<04:53, 32.64s/it, est. speed input: 50.20 toks/s, output: 571.89 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 22/30 [08:41<04:39, 34.96s/it, est. speed input: 48.50 toks/s, output: 581.27 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 23/30 [08:54<03:19, 28.49s/it, est. speed input: 49.34 toks/s, output: 620.37 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 24/30 [09:32<03:08, 31.40s/it, est. speed input: 48.21 toks/s, output: 632.50 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 25/30 [10:12<02:48, 33.74s/it, est. speed input: 47.18 toks/s, output: 645.70 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 26/30 [11:38<03:18, 49.53s/it, est. speed input: 42.93 toks/s, output: 620.27 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:38<00:00, 49.53s/it, est. speed input: 49.64 toks/s, output: 837.88 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [11:38<00:00, 23.28s/it, est. speed input: 49.64 toks/s, output: 837.88 toks/s]
+ CUDA_VISIBLE_DEVICES=0,1
+ python3 /home/x-qlan1/code/moule2/scripts/eval_base/py/eval_aime25.py --model Qwen/Qwen3-8B --mode average --n_samples 16 --temperature 1.2 --top_p 0.95 --max_tokens 38000 --max_model_len 40960 --tp 2 --gpu_memory_utilization 0.9 --output_dir /anvil/scratch/x-qlan1/moule2/eval_results/base
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.
`torch_dtype` is deprecated! Use `dtype` instead!
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
/anvil/scratch/x-qlan1/moule/train-env/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
W0226 21:04:14.753000 3196520 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 21:04:14.753000 3196520 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
W0226 21:04:14.754000 3196519 torch/utils/cpp_extension.py:2425] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W0226 21:04:14.754000 3196519 torch/utils/cpp_extension.py:2425] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards:   0% Completed | 0/5 [00:00<?, ?it/s]
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards:  20% Completed | 1/5 [00:01<00:04,  1.02s/it]
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards:  40% Completed | 2/5 [00:03<00:06,  2.17s/it]
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards:  60% Completed | 3/5 [00:07<00:05,  2.90s/it]
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards:  80% Completed | 4/5 [00:11<00:03,  3.24s/it]
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:15<00:00,  3.40s/it]
[1;36m(Worker_TP0 pid=3196519)[0;0m Loading safetensors checkpoint shards: 100% Completed | 5/5 [00:15<00:00,  3.04s/it]
[1;36m(Worker_TP0 pid=3196519)[0;0m 
[1;36m(Worker_TP0 pid=3196519)[0;0m 2026-02-26 21:05:07,063 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP1 pid=3196520)[0;0m 2026-02-26 21:05:07,064 - INFO - autotuner.py:256 - flashinfer.jit: [Autotuner]: Autotuning process starts ...
[1;36m(Worker_TP0 pid=3196519)[0;0m 2026-02-26 21:05:07,322 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP1 pid=3196520)[0;0m 2026-02-26 21:05:07,328 - INFO - autotuner.py:262 - flashinfer.jit: [Autotuner]: Autotuning process ends
[1;36m(Worker_TP0 pid=3196519)[0;0m Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|â–         | 1/67 [00:00<00:08,  8.13it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|â–         | 3/67 [00:00<00:06, 10.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|â–‹         | 5/67 [00:00<00:05, 10.41it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|â–ˆ         | 7/67 [00:00<00:05, 10.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:05, 10.21it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|â–ˆâ–‹        | 11/67 [00:01<00:05, 10.05it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|â–ˆâ–‰        | 13/67 [00:01<00:05,  9.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|â–ˆâ–ˆâ–       | 15/67 [00:01<00:05,  9.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:01<00:05,  9.92it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:01<00:04, 10.23it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:02<00:04, 10.18it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:02<00:04,  9.97it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:02<00:04,  9.89it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|â–ˆâ–ˆâ–ˆâ–‰      | 26/67 [00:02<00:04,  9.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:02<00:04,  9.90it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 28/67 [00:02<00:03,  9.85it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:02<00:03,  9.74it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 30/67 [00:03<00:03,  9.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:03<00:03,  9.36it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 32/67 [00:03<00:03,  9.42it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:03<00:03,  9.26it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 34/67 [00:03<00:03,  9.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:03<00:03,  9.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 36/67 [00:03<00:03,  9.07it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:03<00:03,  8.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 38/67 [00:03<00:03,  8.87it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:04<00:03,  8.77it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 40/67 [00:04<00:03,  8.75it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:04<00:03,  8.59it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 42/67 [00:04<00:02,  8.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:04<00:02,  8.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 44/67 [00:04<00:02,  8.81it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:04<00:02,  8.91it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 46/67 [00:04<00:02,  8.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:04<00:02,  8.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 48/67 [00:05<00:02,  8.93it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:05<00:02,  8.68it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 50/67 [00:05<00:01,  8.56it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:05<00:01,  8.32it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 52/67 [00:05<00:01,  8.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:05<00:01,  7.46it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 54/67 [00:05<00:01,  7.79it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:05<00:01,  7.82it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 56/67 [00:06<00:01,  7.86it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:06<00:01,  8.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 58/67 [00:06<00:01,  8.27it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:06<00:00,  8.34it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 60/67 [00:06<00:00,  8.24it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:06<00:00,  8.15it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 62/67 [00:06<00:00,  8.06it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:06<00:00,  8.11it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 64/67 [00:07<00:00,  8.17it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:07<00:00,  8.44it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE):  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 66/67 [00:07<00:00,  8.64it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  8.19it/s]Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:07<00:00,  9.05it/s]
[1;36m(Worker_TP0 pid=3196519)[0;0m Capturing CUDA graphs (decode, FULL):   0%|          | 0/67 [00:00<?, ?it/s]Capturing CUDA graphs (decode, FULL):   1%|â–         | 1/67 [00:00<00:07,  8.58it/s]Capturing CUDA graphs (decode, FULL):   4%|â–         | 3/67 [00:00<00:05, 11.40it/s]Capturing CUDA graphs (decode, FULL):   7%|â–‹         | 5/67 [00:00<00:05, 11.99it/s]Capturing CUDA graphs (decode, FULL):  10%|â–ˆ         | 7/67 [00:00<00:04, 12.41it/s]Capturing CUDA graphs (decode, FULL):  13%|â–ˆâ–Ž        | 9/67 [00:00<00:04, 12.58it/s]Capturing CUDA graphs (decode, FULL):  16%|â–ˆâ–‹        | 11/67 [00:00<00:04, 12.78it/s]Capturing CUDA graphs (decode, FULL):  19%|â–ˆâ–‰        | 13/67 [00:01<00:04, 12.60it/s]Capturing CUDA graphs (decode, FULL):  22%|â–ˆâ–ˆâ–       | 15/67 [00:01<00:04, 12.78it/s]Capturing CUDA graphs (decode, FULL):  25%|â–ˆâ–ˆâ–Œ       | 17/67 [00:01<00:03, 13.00it/s]Capturing CUDA graphs (decode, FULL):  28%|â–ˆâ–ˆâ–Š       | 19/67 [00:01<00:03, 12.86it/s]Capturing CUDA graphs (decode, FULL):  31%|â–ˆâ–ˆâ–ˆâ–      | 21/67 [00:01<00:03, 12.90it/s]Capturing CUDA graphs (decode, FULL):  34%|â–ˆâ–ˆâ–ˆâ–      | 23/67 [00:01<00:03, 12.98it/s]Capturing CUDA graphs (decode, FULL):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 25/67 [00:01<00:03, 12.94it/s]Capturing CUDA graphs (decode, FULL):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 27/67 [00:02<00:03, 12.75it/s]Capturing CUDA graphs (decode, FULL):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 29/67 [00:02<00:02, 12.79it/s]Capturing CUDA graphs (decode, FULL):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 31/67 [00:02<00:02, 12.98it/s]Capturing CUDA graphs (decode, FULL):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 33/67 [00:02<00:02, 12.75it/s]Capturing CUDA graphs (decode, FULL):  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 35/67 [00:02<00:02, 12.74it/s]Capturing CUDA graphs (decode, FULL):  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 37/67 [00:02<00:02, 12.87it/s]Capturing CUDA graphs (decode, FULL):  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 39/67 [00:03<00:02, 12.79it/s]Capturing CUDA graphs (decode, FULL):  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 41/67 [00:03<00:02, 12.89it/s]Capturing CUDA graphs (decode, FULL):  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 43/67 [00:03<00:01, 12.96it/s]Capturing CUDA graphs (decode, FULL):  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 45/67 [00:03<00:01, 12.85it/s]Capturing CUDA graphs (decode, FULL):  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 47/67 [00:03<00:01, 12.86it/s]Capturing CUDA graphs (decode, FULL):  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 49/67 [00:03<00:01, 12.92it/s]Capturing CUDA graphs (decode, FULL):  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 51/67 [00:03<00:01, 12.92it/s]Capturing CUDA graphs (decode, FULL):  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 53/67 [00:04<00:01, 12.69it/s]Capturing CUDA graphs (decode, FULL):  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 55/67 [00:04<00:00, 12.67it/s]Capturing CUDA graphs (decode, FULL):  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 57/67 [00:04<00:00, 12.81it/s]Capturing CUDA graphs (decode, FULL):  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 59/67 [00:04<00:00, 12.76it/s]Capturing CUDA graphs (decode, FULL):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 61/67 [00:04<00:00, 12.77it/s]Capturing CUDA graphs (decode, FULL):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 63/67 [00:04<00:00, 12.75it/s]Capturing CUDA graphs (decode, FULL):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 65/67 [00:05<00:00, 12.73it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:05<00:00, 12.74it/s]Capturing CUDA graphs (decode, FULL): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67/67 [00:05<00:00, 12.74it/s]
Adding requests:   0%|          | 0/30 [00:00<?, ?it/s]Adding requests:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 11/30 [00:00<00:00, 95.25it/s]Adding requests:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 21/30 [00:00<00:00, 85.48it/s]Adding requests: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 89.70it/s]
Processed prompts:   0%|          | 0/480 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]Processed prompts:   3%|â–Ž         | 16/480 [03:41<1:47:07, 13.85s/it, est. speed input: 77.17 toks/s, output: 258.32 toks/s]Processed prompts:   7%|â–‹         | 32/480 [04:49<1:01:11,  8.20s/it, est. speed input: 121.12 toks/s, output: 452.17 toks/s]Processed prompts:  10%|â–ˆ         | 48/480 [08:23<1:15:57, 10.55s/it, est. speed input: 104.46 toks/s, output: 542.44 toks/s]Processed prompts:  13%|â–ˆâ–Ž        | 64/480 [10:10<1:02:37,  9.03s/it, est. speed input: 116.19 toks/s, output: 667.04 toks/s]Processed prompts:  17%|â–ˆâ–‹        | 80/480 [11:41<52:15,  7.84s/it, est. speed input: 127.91 toks/s, output: 858.95 toks/s]  Processed prompts:  20%|â–ˆâ–ˆ        | 96/480 [14:40<57:25,  8.97s/it, est. speed input: 122.12 toks/s, output: 932.70 toks/s]Processed prompts:  23%|â–ˆâ–ˆâ–Ž       | 112/480 [18:52<1:08:34, 11.18s/it, est. speed input: 111.34 toks/s, output: 1004.11 toks/s]Processed prompts:  27%|â–ˆâ–ˆâ–‹       | 128/480 [19:07<46:31,  7.93s/it, est. speed input: 127.64 toks/s, output: 1318.06 toks/s]  Processed prompts:  30%|â–ˆâ–ˆâ–ˆ       | 144/480 [19:56<35:53,  6.41s/it, est. speed input: 137.57 toks/s, output: 1384.48 toks/s]Processed prompts:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 160/480 [25:29<57:50, 10.84s/it, est. speed input: 119.57 toks/s, output: 1384.90 toks/s]Processed prompts:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 176/480 [32:56<1:21:29, 16.08s/it, est. speed input: 101.78 toks/s, output: 1127.31 toks/s]Processed prompts:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 192/480 [33:23<56:07, 11.69s/it, est. speed input: 109.02 toks/s, output: 1153.98 toks/s]  Processed prompts:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 208/480 [34:49<44:19,  9.78s/it, est. speed input: 114.00 toks/s, output: 1348.71 toks/s]Processed prompts:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 224/480 [35:24<31:56,  7.49s/it, est. speed input: 120.73 toks/s, output: 1489.86 toks/s]Processed prompts:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 240/480 [35:27<21:08,  5.28s/it, est. speed input: 128.95 toks/s, output: 1678.82 toks/s]Processed prompts:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 256/480 [38:52<28:12,  7.56s/it, est. speed input: 126.02 toks/s, output: 1591.55 toks/s]Processed prompts:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 272/480 [43:24<36:03, 10.40s/it, est. speed input: 119.64 toks/s, output: 1567.19 toks/s]Processed prompts:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 288/480 [47:34<38:17, 11.97s/it, est. speed input: 115.69 toks/s, output: 1612.81 toks/s]Processed prompts:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 304/480 [52:31<40:54, 13.94s/it, est. speed input: 110.53 toks/s, output: 1526.04 toks/s]Processed prompts:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 320/480 [53:25<28:42, 10.77s/it, est. speed input: 114.16 toks/s, output: 1602.19 toks/s]Processed prompts:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 336/480 [54:01<19:42,  8.21s/it, est. speed input: 119.12 toks/s, output: 1701.29 toks/s]Processed prompts:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 352/480 [54:44<14:00,  6.57s/it, est. speed input: 123.02 toks/s, output: 1742.83 toks/s]Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 368/480 [57:41<14:46,  7.92s/it, est. speed input: 122.70 toks/s, output: 1743.72 toks/s]Processed prompts:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 384/480 [59:05<11:21,  7.10s/it, est. speed input: 124.80 toks/s, output: 1756.91 toks/s]Processed prompts:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 400/480 [1:01:23<10:04,  7.56s/it, est. speed input: 125.58 toks/s, output: 1743.81 toks/s]Processed prompts:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 416/480 [1:02:30<06:59,  6.56s/it, est. speed input: 128.69 toks/s, output: 1791.98 toks/s]Processed prompts:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 432/480 [1:03:15<04:20,  5.43s/it, est. speed input: 131.78 toks/s, output: 1846.55 toks/s]Processed prompts:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 448/480 [1:09:23<05:42, 10.71s/it, est. speed input: 124.40 toks/s, output: 1779.11 toks/s]Processed prompts:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 464/480 [1:09:54<02:09,  8.07s/it, est. speed input: 127.82 toks/s, output: 1841.87 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [1:11:24<00:00,  7.34s/it, est. speed input: 129.49 toks/s, output: 1927.23 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [1:11:24<00:00,  7.34s/it, est. speed input: 129.49 toks/s, output: 1927.23 toks/s]Processed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 480/480 [1:11:24<00:00,  8.93s/it, est. speed input: 129.49 toks/s, output: 1927.23 toks/s]
+ wait
+ echo 'All AIME 2025 evaluations completed.'
